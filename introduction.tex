\chapter*{Introduction}

There are several reasons for the interest in the theory of formal languages in
computer science. Practical problems as they arise in the context of the
specification and translation of programming languages find an exact description
in the theory of formal languages and thus get accessible to an exact treatment.
Generation processes definable by formal languages can be interpreted as {\em
non-deterministic automata} which represent conceptual generalizations of a
computer.

These generalizations usually are easier to grasp than deterministic algorithms
which contain more details that do not reflect the original problem but are
determined by the need for unambiguosly defining the algorithm. This is part of
the reason why it is difficult to prove the correctness of programs in a clear
way. Correctness proofs for {\em grammars} or for other language generation
mechanisms offer a possibility to study such proofs on simpler objects.

The theory of formal languages in this respect contains the theory of algorithms
but most often only the theory of {\em context-free languages} is treated
because of her extraordinary simplicity and beauty.

In the foreground of the theory are standing different methods for defining
formal language classes, studying their word and equivalence problems and
putting them into different hierarchical classifications.

The generation processes themselves in the theory also become objects of
interest because the generation process of a language in the case of programming
languages is related to the semantics of the programs.

Of course, in the context of such a pocket book one has to make a close
selection of topics concerning language classes, generation processes as well as
basic questions. In doing that we let us guide by the wish to keep the formal
machinery as small as possible.

Because the theory of finite automata is the foundation of the whole theory of
formal languages, we start our book with that topic. In developing the theory we
do not consider the technical realization of finite automata by logical circuits
and binary storage devices but rather focus on the basic algorithm however it
will get realized. Our intuitive notion of a finite automaton is a {\em finite,
oriented graph} whose edges are labeled with the symbols from the input alphabet
of the automaton. Depending on the input string we look for a path in the graph
labelled with that string. If the end point of a path starting from the
dedicated {\em start point} of the automaton is one of the {\em end points}, our
automaton {\em accepts} the input word and doesn't otherwise.

We prove the equivalence of this concept with the other known methods for
defining finite automata. We prove also the usual closure properties of
languages defined by finite automata. Additionally we investigate the relation
between deterministic and non-deterministic automata and also {\em 2-way
automata}.

It is possible to generalize this theory in the direction of considering not
only the free monoid of strings (words) over a finite alphabet but also
arbitrary monoids.

By considering finite automata with output, that is attaching a second label at
the graph's edges, one gets the {\em rational transducers}. A detailed theory of
these general transductions can be found in the book by Berstel
\cite{Berstel79}.

We restrict ourselves here to special generalizations of the free monoid of
words:
\begin{itemize}
  \item the {\em free group}
  \item the {\em H-group} (the relation $x \cdot x^{-1} = 1$ holds for all $x$
  from the generating system, but not $x^{-1} \cdot x = 1$)
	\item the {\em polycyclic monoid} 
	(in addition to $x \cdot x^{-1} = 1$ it holds $x \cdot y^{-1} = 0$ for $x \neq
	y$ and $0 \cdot x = x \cdot 0 = 0$ for $x,y$ from the generating system)
\end{itemize}

By investigating the {\em transductions} from free monoids into the polycyclic
monoids one gets a smooth transition from the theory of finite automata into
the theory of context-free languages.

The corresponding composition of the theory of context-free languages leads to
a simple path to the most important representation theorems including the
theorems of {\bf Chomsky-Sch√ºtzenberger, Shamir and Greibach}. Also for the
transformation into {\em Greibach normal-form} one gets a simple, efficient
algorithm.

As easy as in the case of finite automata one can prove the known closure
properties for context-free languages.

Finally we also prove the equivalence of this representation to the
usual representation of context-free languages by context-free grammars.

Our composition of the theory is very close to the one repeatedly recommended by
Goldstine since 1977 but originated independently. The difference is that we
prove Greibach's representation theorem by making our automaton deterministic 
going from output monoids to {\em monoid rings}. In doing so one gets the
theorem of Shamir in a natural way and from this the theorem of Greibach.

From the theorem of Shamir one can quite easily get the algorithm of Valiant
for deciding the {\em word problem} of context-free languages. Because of lack
of space this could not be included into this book, the same holds true for the
treatment of the deterministic languages.

We want to emphasize at this point another advantage of this composition of the
theory: As known, the exact formalization of the notion of {\em derivation} 
brings some difficulties when using grammars. In our theory the {\em derivation
tree} corresponds to a path in a graph.

Maybe the use of non-free monoids is initially a problem for readers who are not
used to that. But it seems to be the case that defining context-free
languages in that way supports intuition. For example, the usage of
{\em syntax diagrams} in the definition of programming languages gives some
evidence for this.

Because we judge the former fact as rather important, we want to explain it on a
specific example, the so-called {\em Dyck language}.

\transrem{In the literature, the Dyck language is also defined such that
corresponding brackets are symmetric. The language defined here is called 
{\em Semi-Dyck language} in that case.}

\index{Dyck language}
The {\em Dyck language} $D(X_k)$ contains the correctly nested bracket sequences
over $k$ different pairs of brackets, $k \in \mathbb{N}$. Formal definition:

Let $X_k = \{ x_1, \ldots, x_k \}$ be an alphabet of $k$ elements. Define
$\bar{X}_k = \{ \bar{x}_1, \ldots, \bar{x}_k \}$ such that $\bar{x}_i$ is regarded 
as the closing bracket for $x_i$.

Then it holds:
\begin{enumerate}
  \item $\epsilon \in D(X_k)$
  \item $u, v \in D(X_k) \Rightarrow u \cdot v \in D(X_k)$
  \item $u \in D(X_k) \Rightarrow x_i \cdot u \cdot \bar{x}_i \in D(X_k),\quad i
  = 1, \ldots, k$
  \item $D(X_k)$ is minimal with (1), (2) and (3). 
\end{enumerate}

For $D(X_k)$ we get the following {\em syntax diagram}:

\begin{center}
\input{figures/dyck.tikz}
\end{center}

If we consider all labellings of paths from vertex $s$ to vertex $f$ we get of
course also words not contained in $D(X_k)$ like for example $x_1 x_2
\bar{x}_k$ or $x_1 \bar{x}_1 \bar{x}_2$ etc.

We have to guarantee that we get Dyck words only. 

To do that, we define a {\em homomorphism} from the paths of the graph into the
polycyclic monoid over $X_k \cup \bar{X}_k$ such that the homomorphic images of
the paths from $S$ to $F$ have a special form, for example are equal to the unit
of the polycyclic monoid.

If we consider the word $ x_1 x_2 \bar{x}_2 \bar{x}_1 x_2 \bar{x}_2 \in D(X_2)$
then we have different paths 
\[e_{x_1} e_2 e_{x_2} e_{\bar{x}_2} e_3 e_{\bar{x}_1} e_1 e_{x_2} e_{\bar{x}_2} \] 
and 
\[e_{x_1} e_2 e_{x_2} e_{\bar{x}_2} e_3 e_{\bar{x}_1} e_3 e_2 e_{x_2}
e_{\bar{x}_2}\] 
which both have this word as label and we can easily define a homomorphism in
the sense given above fulfilling the condition.

We get different paths in our graph leading to the acceptance of the same word.

The problem of constructing a graph such that for each word in the accepted
language exactly one path exists leads to the existence of the {\em
deterministic finite automaton with storage}.

\transrem{Finite automata with storage monoids have gained interest
in current research on computational algebra and automata theory, see for
example \cite{doi:10.1080/00927870802243580} and \cite{Render}.}
