\section{The theorem of Chomsky-Schützenberger}

The Chomsky-Schützenberger theorem is one of the fundamental theorems in the
theory of formal languages, especially the context-free languages \cite{ChSch}.

In the literature, the proof of this theorem is always based on grammars.

We will give an automata-theoretic access to this theorem. We present this
theorem at this point in the book because from a proof technical point of
view it can very well be appended to the section on pushdown languages
(chapter III.1). A similar access to this theorem has been given by Goldstine
 \cite{Goldstine77,Goldstine79,Goldstine80}.

The Chomsky-Schützenberger theorem characterizes the context-free languages
by a very simple subclass of context-free languages with the use of a
homomorphism.

In this respect the theorem is an analogon to lemma 7 in chapter II.1 where we
proved that each regular language can be presented as the homomorphic image of
a local language.

We want to formulate the theorem now.

Let $D(\Sigma)$ be the Dyck language over the alphabet $\Sigma$ (see chapter
I.3, page \pageref{dyck-language}).

Remark: In the literature, often the language \[ \setof{w\in
(\unioninv{\Sigma})^* \mid |w|= \epsilon\text{ in the free group }F(\Sigma)} \]
is called Dyck language. We denote that language as the {\em symmetric} Dyck
language.

With our notations the following theorem holds:
\begin{theorem}[Chomsky-Schützenberger] For each language $L\in \alglang(X^*)$
there exists
\begin{itemize}
  \item[] an alphabet $\Sigma \subset X_\infty$,
  \item[] a regular set $R\in \reglang((\unioninv{\Sigma})^*)$ and
  \item[] a monoid homomorphism $\phi: (\unioninv{\Sigma})^* \to X^*$ such that
\end{itemize}
\[ L = \phi(D(\Sigma)\cap R) \]
\end{theorem}

(The proof in the original book was somewhat hard to read and has been
reformulated therefore.)

\begin{proof}
For each language $L\in \alglang(X^*)$ there exists a PDA
$\kappa=(\fa{A}, \store{K})$ with $L = L_\kappa$. Here, $\fa{A} = (G, X, S, F,
\alpha)$ is a finite automaton with graph $G=(V, E)$ and $\store{K} = (E, Y,
\delta)$ is a simple pushdown store.

For the proof we use the graph $G'=(V',E'),\ V' = V \cup \setof{s_0}$ we
constructed in theorem 2 of section III.1 and the mapping $\gamma: E' \to
\hgroup{Y}$ which encodes the pushdown computations by elements from the
H-group over $Y$.

The graph $G'$ has the following types of edges:
\begin{itemize}
  \item A start edge $e'_s \in \setof{s_0} \times S$ labelled by $y_0$ 
  \[ e'_s: s_0 \edge{y_0} s \] 
  for each start vertex $s \in S$.
  
  \item ''PUSH($z$)''-edges $e'=(e, y) \in E \times Y$ of the form
  \[ e': Q(e) \edge{y^{-1} y z} Z(e) \]
  for each edge $e \in E$ with $\delta(e, y) = yz$ and $|yz| \neq \epsilon$. 
  
  The prefix $y^{-1} y$ realizes the non-deterministic guess of the topmost
  stack symbol $y$.
  
  \item ''Empty-stack''-edges $e'=(e, y) \in E \times Y$ of the form
  \[ e': Q(e) \edge{y_0^{-1} y_0 \cdot \delta(e, \epsilon)} Z(e) \]
  for each edge $e \in E$.
  
  The prefix $y_0^{-1} y_0$ realizes the non-deterministic guess of the
  empty-stack symbol $y_0$.
  
  \item ''POP($z$)''-edges $e'=(e, z, y) \in E \times Y \times Y_0$ of the form
  \[ e': Q(e) \edge{z^{-1} y^{-1} y} Z(e) \]
  for each edge $e \in E$ with $\delta(e, z) = \epsilon$.
  
  The suffix $y^{-1} y$ realizes the non-deterministic guess of the topmost
  stack symbol $y$ after the symbol $z$ has been popped.
\end{itemize}

Our goal is to construct from $G'$ a graph $\tilde{G}$ whose edges will
constitute the alphabet $\Sigma \cup \Sigma^{-1}$ of the Dyck language.

First we define a relation $\rho' \subset E' \times E'$ on the edges of the
graph $G'$. $\rho'$ relates two edges if they represent a pair of
corresponding push/pop-operations.

For edges $e', f' \in E'$ define
\begin{eqnarray*}
(e', f') \in \rho' & \iff & e' = (e, y)\text{ with }\delta(e, y) =
y z \\
&& f' = (f, z, y)\text{ with }\delta(f, z) = \epsilon \\
&& e, f \in E,\ y,z \in Y
\end{eqnarray*} 

Consider a path in the graph $G$ of the original pushdown automaton:

\begin{center}
\input{figures/chapter3-3-theorem1-path-in-g.tikz}
\end{center}

The corresponding path in the graph $G'$:

\begin{center}
\input{figures/chapter3-3-theorem1-path-in-gprime.tikz}
\end{center}

The relation $\rho'$ between the edges of $G'$ can be visualized as a bipartite
graph:

\begin{center}
\input{figures/chapter3-3-theorem1-bipartite-1.tikz}
\end{center}

The edges of this relation connect each edge from $E'$ representing an 
''opening bracket'' (push-operation) with those edges from $E'$
representing the corresponding ''closing bracket'' (pop-operation).

To get a one-to-one relation, the edges of the relation $\rho'$ are multiplied
as needed. The result is a new relation $\tilde{\rho}$ in which each
opening bracket has a unique closing bracket:

\begin{center}
\input{figures/chapter3-3-theorem1-bipartite-2.tikz}
\end{center}

The edges that have been created by multiplying an edge $e' \in E'$ are called
the {\em parallel edges} of $e'$.

For edges $(\tilde{e}, \tilde f) \in \tilde{\rho}$ we also write $\tilde f =
\inv{\tilde e}$ and call $\tilde f$ the {\em inverse edge} to $\tilde e$.

In the graph $\tilde{G}$ we replace the edges of $G'$ by their parallel edges:

\begin{center}
\input{figures/chapter3-3-theorem1-parallel-edges.tikz}
\end{center}

A parallel edge $e'[i] \in \tilde E$ has the same source and target as
the original edge $e' \in G'$:
\[ Q(e'[i]) = Q(e'),\quad Z(e'[i]) = Z(e') \]

By our construction it holds:
If $(e', f') \in \rho'$ then there exists exactly one pair of parallel edges
$(\tilde e, \tilde f) \in \tilde\rho$ such that $\tilde f = \inv{\tilde e}$.

From $G'$ we construct the graph $\tilde{G} = (\tilde{V}, \tilde{E})$ by setting
\begin{eqnarray*}
\tilde{V} &:=& V' \ (=V \cup \setof{s_0}) \\
\tilde{E} &:=& \setof{\tilde e \mid \tilde e \text{ is parallel edge for
some }e' \in E'}
\end{eqnarray*}

If $\tilde e \in \tilde{E}$ is a parallel edge for some $e' \in E'$ we write:
\[ e' = \proj{\tilde e}\quad (e'\text{ is the projection of }\tilde e \] 

For each path $\tilde{\pi} \in \pathcat{\tilde{G}}$ then holds
$\proj{\tilde{\pi}} \in \pathcat{G'}$, i.e.\ the paths of parallel edges are
projected to paths in $G'$.

\newcommand{\validpaths}{\mathrm{VP}}
We define the set of {\em valid paths} in $\tilde{G}$ by
\begin{eqnarray*}
\validpaths &=& \{ \tilde e_1 \cdots \tilde e_k \in \pathcat{\tilde{G}}
\mid \tilde{e_i} \in \tilde{E} \\
& & \text{and for each pair }(\tilde e_i, \tilde e_{i+1})\text{ of consecutive
edges holds:}\\
& & \gamma(\proj{\tilde{e}_i} \cdot \proj{\tilde{e}_{i+1}}) \not\equiv 0\text{
in the polycyclic monoid }\pocymon{Y} \,\}
\end{eqnarray*}

\newcommand{\acceptedpaths}{\mathrm{VAP}}
We define the set of {\em valid accepted} paths in $\tilde{G}$ by
\begin{equation*}
\acceptedpaths = \setof{\tilde\pi \in \validpaths \mid Q(\tilde\pi) \in
S,\ Z(\tilde\pi) \in F} \subset \validpaths
\end{equation*}

Note that $\validpaths$ and $\acceptedpaths$ both are {\em local} sets.

\medskip
We define the (positive) alphabet $\Sigma$ as the set of those parallel edges
that are projected to edges which execute a push-operation:
\begin{equation*}
\Sigma := \tilde{E}^+ := \setof{\tilde e \in \tilde{E} \mid \proj{\tilde e} =
(e, y) \in E \times Y}
\end{equation*}

Then the edge set of the graph $\tilde{G}$ is divided into $\tilde{E}
= \tilde{E}^+ \cup \tilde{E}^-$.

For the proof of the theorem we need two lemmata.

A path in $\tilde{G}$ is called {\em well-nested} if it can be reduced to the
empty path using the relations 
\[ \tilde{e} \cdot \inv{\tilde{e}} = \epsilon,\quad \tilde{e}, \inv{\tilde{e}}
\in E'\]

(The lemma from the original book has been reformulated.)

\begin{lemma}
If $\tilde{\pi} \in \validpaths$ is a non-empty valid path and $\tilde\pi$ is
well-nested, then for the projection $\pi' = \proj{\tilde{\pi}}$ holds:
\[ |\gamma(\pi')| = y \inv{y}\text{ for some }y \in Y \]
\end{lemma}

\begin{proof}
The proof uses induction over the path length. Observe that a well-nested
path has even length, therefore a well-nested, non-empty path has length at
least two.

Remember the definition of the Dyck language $D(\Sigma)$ over an alphabet
$\Sigma$:
\begin{eqnarray*}
d \in D(\Sigma) &\Rightarrow& \sigma \cdot d \cdot \inv{\sigma} \in
D(\Sigma)\text{ for each }\sigma \in \Sigma \\
d_1, d_2 \in D(\Sigma) &\Rightarrow& d_1 \cdot d_2 \in D(\Sigma)
\end{eqnarray*}

{\em Induction base:} $\len{\tilde{\pi}}=2$
\begin{eqnarray*}
\tilde{\pi} = \tilde e \cdot \inv{\tilde e} &\Rightarrow& (\tilde e, \inv{\tilde
e}) \in \tilde{\rho} \\
&\Rightarrow& (\proj{\tilde e}, \proj{\inv{\tilde e}}) \in \rho'\text{ where }\\
&& \proj{\tilde e} \in E \times Y\text{ is a ''push''-edge and} \\
&& \proj{\inv{\tilde e}} \in E \times Y \times Y_0\text{ is the
corresponding ''pop''-edge}
\end{eqnarray*}

$\proj{\tilde{\pi}} = \proj{\tilde e} \cdot \proj{\inv{\tilde e}}$

If
\begin{eqnarray*}
\gamma(\proj{\tilde e}) &=& \inv{y} y z \qquad\text{(''guess $y$;\ push $z$'')}
\\
\gamma(\proj{\inv{\tilde e}}) &=& \inv{z} \inv{y} y \qquad\text{(''pop $z$;\
guess $y$'')} \\
\text{then} \\
|\gamma(\proj{\tilde{\pi}})| &=& |\gamma(\proj{\tilde e}) \cdot
\gamma(\proj{\inv{\tilde e}})| \\
&=& |\inv{y} y z \cdot \inv{z} \inv{y} y| \\
&=& |\inv{y} y (z \cdot \inv{z}) \inv{y} y| \\
&=& |\inv{y} (y \inv{y}) y| \\
&=& |\inv{y} y| \\
&=& \inv{y} y
\end{eqnarray*}

\medskip
{\em Induction step:}

{\em Case 1:} Let the claim be true for a well-nested path $\tilde{\pi}$. Then
$|\tilde{\pi}| = \epsilon$ and for the projection $\proj{\tilde{\pi}}$ holds
\[ |\gamma(\proj{\tilde{\pi}})| = \inv{y_1} \cdot y_1\text{ for some }y_1 \in Y
\]

Consider the path $\tilde e \cdot \tilde{\pi} \cdot \inv{\tilde e}.$ It is
well-nested because $\tilde\pi$ is well-nested.

For the projection
\[ \proj{\tilde e \cdot \tilde{\pi} \cdot \inv{\tilde e}} = \proj{\tilde e}
\cdot \proj{\tilde{\pi}} \cdot \proj{\inv{\tilde e}} \in \pathcat{G'} \]
where
\begin{eqnarray*}
\proj{\tilde e} &=& (e_1, y) \qquad\text{''push $z$-edge''}\\
\proj{\inv{\tilde e}} &=& (e_2, z, y) \qquad\text{''pop $z$-edge''}\\
\end{eqnarray*}
we get:
\begin{eqnarray*}
|\gamma(\proj{\tilde e} \cdot \proj{\tilde{\pi}} \cdot \proj{\inv{\tilde
e}})|&=& |\gamma(\proj{\tilde e}) \cdot \gamma(\proj{\tilde{\pi}}) \cdot
\gamma(\proj{\inv{\tilde e}})| \\
&=&|\gamma((e_1, y)) \cdot  (\inv{y_1} y_1) \cdot \gamma((e_2, z, y))| \\
&=& |(\inv{y} \cdot y \cdot z) \cdot (\inv{y_1} \cdot y_1) \cdot (\inv{z} \cdot
\inv{y} \cdot y)| \\
\end{eqnarray*}
Because $\tilde e \cdot \tilde{\pi} \cdot \inv{\tilde e}$ is well-nested it
must hold $z = y_1$. Otherwise from $z \cdot \inv{y_1} \equiv 0$ would
follows $e \cdot \tilde{\pi} \cdot \inv{e} \equiv 0$ which would be a 
contradiction to our assumptions.

Therefore
\begin{eqnarray*}
|(\inv{y} \cdot y \cdot z) \cdot (\inv{y_1} \cdot y_1) \cdot (\inv{z} \cdot
\inv{y} \cdot y)| &=&
|(\inv{y} \cdot y \cdot z) \cdot (\inv{z} \cdot z) \cdot (\inv{z} \cdot
\inv{y} \cdot y)| \\
&=& |\inv{y} \cdot (y \cdot (z \cdot \inv{z}) \cdot (z \cdot \inv{z}) \cdot
\inv{y}) \cdot y| \\
&=& |\inv{y} \cdot (y \cdot \inv{y}) \cdot y| \\
&=& |\inv{y} \cdot y| \\
&=& \inv{y}  \cdot y
\end{eqnarray*}

\medskip
{\em Case 2:} Let $\tilde{\pi} = \tilde{\pi}_1 \cdot \tilde{\pi}_2$ be a valid
path which is the product of two well-nested paths, i.e.\ $|\tilde{\pi}_1| =
|\tilde{\pi}_2| = \epsilon$.

Consider
\begin{eqnarray*}
|\gamma(\proj{\tilde{\pi}})| &=& |\gamma(\proj{\tilde{\pi}_1 \cdot
\tilde{\pi}_2})| \\
&=& |\gamma(\proj{\tilde{\pi}_1}) \cdot \gamma(\proj{\tilde{\pi}_2})| \\
&=& (\inv{y_1} \cdot y_1) \cdot (\inv{y_2} \cdot y_2),\text{ for some }y_1, y_2
\in Y\text{ by induction hypothesis}
\end{eqnarray*}

Because $\tilde{\pi}_1 \cdot \tilde{\pi}_2$ is valid, it must hold $y_1 = y_2$.
Otherwise it would be $y_1 \cdot \inv{y_2} \equiv 0$ which would violate our 
assumptions.

Therefore we get
\begin{eqnarray*}
|\gamma(\proj{\tilde{\pi}})| &=& (\inv{y_1} \cdot y_1) \cdot (\inv{y_2} \cdot
y_2)\\
&=& \inv{y_1} \cdot y_1 \cdot \inv{y_1} \cdot y_1 \\
&=& \inv{y_1} \cdot y_1
\end{eqnarray*}
\end{proof}

The lemma of course also holds for well-nested {\em accepted paths}. For the
projection of such a path $\tilde\pi \in \acceptedpaths,\ \tilde\pi \equiv
\epsilon$,  holds 
\[ \pi = \proj{\tilde{\pi}} \in \pathcat{G'}(S, F) \Rightarrow |\gamma(\pi)| =
\inv{y_0} y_0 \]
where $y_0$ is the special symbol in the pushdown alphabet.

\bigskip
\begin{lemma}
For each path $\pi' \in \pathcat{G'}$ with
\[ |\gamma(\pi')| = \inv{y} y \quad\text{for some }y \in Y \]
there exists exactly one path $\tilde{\pi} \in \validpaths$ with 
\[ |\tilde{\pi}| = \epsilon\text{ and }\pi' = \proj{\tilde{\pi}} \] 
\end{lemma}

\begin{proof}
TODO
\end{proof}

Similar as after lemma 1 one can conclude here that for each path $\pi' \in
\pathcat{G'}(S, F)$ with $|\gamma(\pi')| = \inv{y_0} y_0$ there exists exactly
one well-nested path $\tilde{\pi} \in \acceptedpaths$ with $\proj{\tilde{\pi}} =
\pi'$ and $|\tilde{\pi}| = \epsilon$.

\medskip
Using both lemmata we can now prove the theorem:
\begin{eqnarray*}
L_\kappa &=& \setof{\alpha(\pi) \mid \pi \in \pathcat{G}(S, F),\ \delta(\pi,
\epsilon) = \epsilon}\text{ (by definition of PDA)} \\
&=& \setof{\alpha(\pi') \mid \pi' \in \pathcat{G'}(s_0, F),\ |\gamma(\pi')| =
y_0}\text{ (by theorem 2, chapter III.1)} \\
&=& \setof{\alpha(\pi') \mid \pi' \in \pathcat{G'}(S, F),\
|\gamma(\pi')| = \inv{y_0} y_0}\text{ (by construction of $G'$)}
\end{eqnarray*}

If we define $R := \acceptedpaths$, we get $R \in \reglang(\unioninv{\Sigma})^*$
because every local language is regular.

Together with lemma 1 and lemma 2 it follows
\[ \proj{R \cap D(\underbrace{\tilde{E}^+}_{\Sigma})} = \setof{\pi' \in
\pathcat{G'}(s_0, F) \mid |\gamma(\pi')| = y_0} \]

With the homomorphism
\[ \phi := (\mathbf{p} \circ \alpha) : (\unioninv{\Sigma})^* \to X^* \]
we get
\[ L_\kappa = \phi(D(\Sigma) \cap R) \]
\end{proof}

We even proved slightly more: Let 
\[ {<}\kappa, w{>} := \card{\setof{\pi \in
\pathcat{G}(S,F) \mid \alpha(\pi) = w,\ \delta(\pi, \epsilon) = \epsilon}}
\]
be the number of accepting computations of the PDA $\kappa$ for the word $w$.

\begin{corollary}
For each PDA $\kappa$ there exists a Dyck language $D(\Sigma)$ and a local set
$R$ over $\unioninv{\Sigma}$ and a monoid homomorphism $\phi:
(\unioninv{\Sigma})^* \to X^*$ such that
\begin{enumerate}
  \item $\phi(D(\Sigma\cap R)) = L_\kappa$
  \item For $w\in X^*$ it holds ${<}\kappa, w{>} = \card{\phi^{-1}(w)}$
\end{enumerate}
\end{corollary}

\begin{proof}\ 

\begin{enumerate}
  \item Chomsky-Schützenberger theorem
  \item Follows from the construction in the proof. (The inverse homomorphism
  gives the different accepting computations for a word.)
\end{enumerate}
\end{proof}

Problem: Is it possible to always find a PDA $\kappa$ accepting 
$L \in \alglang(X^*)$ such that for each word $w$ it holds 
${<}\kappa, w{>} < \infty$?

If the definition of the pushdown store is generalized such that $\delta(X
\times Y) \subset Y^*$ is allowed, is then the condition ${<}\kappa, w{>} <
\infty$ always satisfiable?

This problem will be investigated in a later chapter.

\medskip
At the end of this section, for interested readers we want to mention the
following:

The Dyck language $D(X) \in \alglang(X_\infty^*)$ is algebraic.

By theorem 1 in section III.2 it holds that the class of algebraic languages is
closed under monoid homomorphism, and by theorem 3 in chapter III.2 also closed
under intersection with regular sets.

From the Chomsky-Schützenberger theorem therefore follows that the class of
algebraic languages over the alphabet $X_\infty$ is exactly the class of
context-free languages.
